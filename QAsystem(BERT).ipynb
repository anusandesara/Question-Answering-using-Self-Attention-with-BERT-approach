{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "QAsystem(BERT).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iAQg8q1MZIc"
      },
      "source": [
        "# importing all necessary files\n",
        "\n",
        "import zipfile\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "import sys\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import json\n",
        "import six\n",
        "\n",
        "from collections import Counter\n",
        "import string\n",
        "import re\n",
        "import argparse\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EvhfJDfbKM7"
      },
      "source": [
        "## Configuring TPU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "pUX8reoFHGk4",
        "outputId": "6367eead-26c7-484a-a8a3-c84bcf6cd8dd"
      },
      "source": [
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.12.236.42:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0827 05:51:10.907844 140491252946816 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 11440417705514041917),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 11361402579519159698),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 12357697597335777241),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 7898279176896720777),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 16769548510779700091),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 9684062799403801468),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 18088205161317314166),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 2719725766142665814),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 12910852574047901557),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 9410472538681109359),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 15068353228979054653)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcQLA51nosTN"
      },
      "source": [
        "**import necessary BERT modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "3ZEclFB0Hbyz",
        "outputId": "970acfc1-5173-42ad-a352-463560191cc4"
      },
      "source": [
        "import sys\n",
        "\n",
        "!test -d bert_repo || git clone https://github.com/google-research/bert bert_repo\n",
        "if not 'bert_repo' in sys.path:\n",
        "  sys.path += ['bert_repo']\n",
        "\n",
        "# import python modules defined by BERT\n",
        "import run_squad\n",
        "import modeling\n",
        "import optimization\n",
        "import tokenization\n",
        "import tensorflow as tf\n",
        "import tokenization\n",
        "\n",
        "# import tfhub \n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert_repo'...\n",
            "remote: Enumerating objects: 333, done.\u001b[K\n",
            "remote: Total 333 (delta 0), reused 0 (delta 0), pack-reused 333\u001b[K\n",
            "Receiving objects: 100% (333/333), 282.46 KiB | 3.98 MiB/s, done.\n",
            "Resolving deltas: 100% (183/183), done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0827 06:05:06.749072 140491252946816 deprecation_wrapper.py:119] From bert_repo/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQk3_1S8o8at"
      },
      "source": [
        "**This next section of code performs the following tasks:**\n",
        "\n",
        "*  Specify BERT pretrained model [uncased_L-12_H-768_A-12]\n",
        "*  Create output directory for model checkpoints and eval results.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "6a4ShppsH_N9",
        "outputId": "967157cb-a37d-4290-b23a-79016219092f"
      },
      "source": [
        "TASK = 'SQUAD' #@param {type:\"string\"}\n",
        "assert TASK in ('MRPC', 'CoLA',\"SQUAD\"), 'Only (MRPC, CoLA) are demonstrated here.'\n",
        "\n",
        "\n",
        "BUCKET = 'bert-on-squad' #@param {type:\"string\"}\n",
        "assert BUCKET, 'Must specify an existing GCS bucket name'\n",
        "OUTPUT_DIR = 'gs://{}/bert-tfhub/models/{}'.format(BUCKET, TASK)\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n",
        "\n",
        "# Available pretrained model checkpoints:\n",
        "#   uncased_L-12_H-768_A-12: uncased BERT base model\n",
        "#   uncased_L-24_H-1024_A-16: uncased BERT large model\n",
        "#   cased_L-12_H-768_A-12: cased BERT large model\n",
        "BERT_MODEL = 'uncased_L-12_H-768_A-12' #@param {type:\"string\"}\n",
        "BERT_MODEL_HUB = 'https://tfhub.dev/google/bert_' + BERT_MODEL + '/1'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Model output directory: gs://bert-on-squad/bert-tfhub/models/SQUAD *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OA0Qj3h_NNY3"
      },
      "source": [
        "# Setup TPU related config\n",
        "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "NUM_TPU_CORES = 8\n",
        "ITERATIONS_PER_LOOP = 1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "eNKaOOjHOXNB",
        "outputId": "19be3601-9673-4506-e45a-d83a1f6cae06"
      },
      "source": [
        "# Setup task specific model and TPU running config.\n",
        "BERT_PRETRAINED_DIR = 'gs://cloud-tpu-checkpoints/bert/' + BERT_MODEL \n",
        "print('***** BERT pretrained directory: {} *****'.format(BERT_PRETRAINED_DIR))\n",
        "!gsutil ls $BERT_PRETRAINED_DIR\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** BERT pretrained directory: gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12 *****\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_config.json\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_model.ckpt.index\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_model.ckpt.meta\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/checkpoint\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MdBSAQDPNej"
      },
      "source": [
        "# seting up necessary path files for models\n",
        "CONFIG_FILE = os.path.join(BERT_PRETRAINED_DIR, 'bert_config.json')\n",
        "INIT_CHECKPOINT = os.path.join(BERT_PRETRAINED_DIR, 'bert_model.ckpt')\n",
        "VOCAB_FILE = os.path.join(BERT_PRETRAINED_DIR, 'vocab.txt')\n",
        "DO_LOWER_CASE = BERT_MODEL.startswith('uncased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98wc25FnPp4A"
      },
      "source": [
        "OUTPUT_DIR = OUTPUT_DIR.replace('bert-tfhub', 'bert-checkpoints')\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAExipC-bF60"
      },
      "source": [
        "## Get SQUAD Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPNBY2ekdrqr"
      },
      "source": [
        "with zipfile.ZipFile(\"/content/train-v1.1.json.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "    \n",
        "with zipfile.ZipFile(\"/content/dev-v1.1.json.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWIyWoKvsYPs"
      },
      "source": [
        "### Important Functions:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQITcyy8s8yc"
      },
      "source": [
        "**read_squad_examples :**\n",
        "This function takes input as **json** file and retunrs the object of SquadExample claas. Which is nothing but, container storinng our each data point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN_YXPZrcL3l"
      },
      "source": [
        "def read_squad_examples(input_file, is_training):\n",
        "  \"\"\"Read a SQuAD json file into a list of SquadExample.\"\"\"\n",
        "  with tf.gfile.Open(input_file, \"r\") as reader:\n",
        "    input_data = json.load(reader)[\"data\"]\n",
        "\n",
        "  def is_whitespace(c):\n",
        "    if c == \" \" or c == \"\\t\" or c == \"\\r\" or c == \"\\n\" or ord(c) == 0x202F:\n",
        "      return True\n",
        "    return False\n",
        "\n",
        "  examples = []\n",
        "  for entry in input_data:\n",
        "    for paragraph in entry[\"paragraphs\"]:\n",
        "      paragraph_text = paragraph[\"context\"]\n",
        "      doc_tokens = []\n",
        "      char_to_word_offset = []\n",
        "      prev_is_whitespace = True\n",
        "      for c in paragraph_text:\n",
        "        if is_whitespace(c):\n",
        "          prev_is_whitespace = True\n",
        "        else:\n",
        "          if prev_is_whitespace:\n",
        "            doc_tokens.append(c)\n",
        "          else:\n",
        "            doc_tokens[-1] += c\n",
        "          prev_is_whitespace = False\n",
        "        char_to_word_offset.append(len(doc_tokens) - 1)\n",
        "\n",
        "      for qa in paragraph[\"qas\"]:\n",
        "        qas_id = qa[\"id\"]\n",
        "        question_text = qa[\"question\"]\n",
        "        start_position = None\n",
        "        end_position = None\n",
        "        orig_answer_text = None\n",
        "        is_impossible = False\n",
        "        if is_training:\n",
        "\n",
        "          if False:\n",
        "            is_impossible = qa[\"is_impossible\"]\n",
        "          if (len(qa[\"answers\"]) != 1) and (not is_impossible):\n",
        "            raise ValueError(\n",
        "                \"For training, each question should have exactly 1 answer.\")\n",
        "          if not is_impossible:\n",
        "            answer = qa[\"answers\"][0]\n",
        "            orig_answer_text = answer[\"text\"]\n",
        "            answer_offset = answer[\"answer_start\"]\n",
        "            answer_length = len(orig_answer_text)\n",
        "            start_position = char_to_word_offset[answer_offset]\n",
        "            end_position = char_to_word_offset[answer_offset + answer_length -\n",
        "                                               1]\n",
        "           \n",
        "            actual_text = \" \".join(\n",
        "                doc_tokens[start_position:(end_position + 1)])\n",
        "            cleaned_answer_text = \" \".join(\n",
        "                tokenization.whitespace_tokenize(orig_answer_text))\n",
        "            if actual_text.find(cleaned_answer_text) == -1:\n",
        "              tf.logging.warning(\"Could not find answer: '%s' vs. '%s'\",\n",
        "                                 actual_text, cleaned_answer_text)\n",
        "              continue\n",
        "          else:\n",
        "            start_position = -1\n",
        "            end_position = -1\n",
        "            orig_answer_text = \"\"\n",
        "\n",
        "        example = run_squad.SquadExample(\n",
        "            qas_id=qas_id,\n",
        "            question_text=question_text,\n",
        "            doc_tokens=doc_tokens,\n",
        "            orig_answer_text=orig_answer_text,\n",
        "            start_position=start_position,\n",
        "            end_position=end_position,\n",
        "            is_impossible=is_impossible)\n",
        "        examples.append(example)\n",
        "\n",
        "  return examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "eyZubuOEc1YE",
        "outputId": "c7f179b4-471d-463c-8ea1-79d8a0b24783"
      },
      "source": [
        "train_examples = read_squad_examples(\"/content/train-v1.1.json\",True)\n",
        "print(\"Total train examples are \",len(train_examples))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total train examples are  87599\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "wtx6cVPdrsL9",
        "outputId": "29579dba-0e85-4b6d-85c2-5d4d7a017617"
      },
      "source": [
        "print(\"Type of return :\\n\",type(train_examples[0]))\n",
        "print(\"*\"*60)\n",
        "print(\"Question ID : \",train_examples[0].qas_id)\n",
        "print(\"*\"*60)\n",
        "print(\"question_text : \",train_examples[0].question_text)\n",
        "print(\"*\"*60)\n",
        "print(\"doc_tokens : \",train_examples[0].doc_tokens)\n",
        "print(\"*\"*60)\n",
        "print(\"start_position : \",train_examples[0].start_position)\n",
        "print(\"end_position : \",train_examples[0].end_position)\n",
        "print(\"*\"*60)\n",
        "print(\"is_impossible : \",train_examples[0].is_impossible)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type of return :\n",
            " <class 'run_squad.SquadExample'>\n",
            "************************************************************\n",
            "Question ID :  5733be284776f41900661182\n",
            "************************************************************\n",
            "question_text :  To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
            "************************************************************\n",
            "doc_tokens :  ['Architecturally,', 'the', 'school', 'has', 'a', 'Catholic', 'character.', 'Atop', 'the', 'Main', \"Building's\", 'gold', 'dome', 'is', 'a', 'golden', 'statue', 'of', 'the', 'Virgin', 'Mary.', 'Immediately', 'in', 'front', 'of', 'the', 'Main', 'Building', 'and', 'facing', 'it,', 'is', 'a', 'copper', 'statue', 'of', 'Christ', 'with', 'arms', 'upraised', 'with', 'the', 'legend', '\"Venite', 'Ad', 'Me', 'Omnes\".', 'Next', 'to', 'the', 'Main', 'Building', 'is', 'the', 'Basilica', 'of', 'the', 'Sacred', 'Heart.', 'Immediately', 'behind', 'the', 'basilica', 'is', 'the', 'Grotto,', 'a', 'Marian', 'place', 'of', 'prayer', 'and', 'reflection.', 'It', 'is', 'a', 'replica', 'of', 'the', 'grotto', 'at', 'Lourdes,', 'France', 'where', 'the', 'Virgin', 'Mary', 'reputedly', 'appeared', 'to', 'Saint', 'Bernadette', 'Soubirous', 'in', '1858.', 'At', 'the', 'end', 'of', 'the', 'main', 'drive', '(and', 'in', 'a', 'direct', 'line', 'that', 'connects', 'through', '3', 'statues', 'and', 'the', 'Gold', 'Dome),', 'is', 'a', 'simple,', 'modern', 'stone', 'statue', 'of', 'Mary.']\n",
            "************************************************************\n",
            "start_position :  90\n",
            "end_position :  92\n",
            "************************************************************\n",
            "is_impossible :  False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxDYT4Rw0cyH"
      },
      "source": [
        "**Write Predicitons :**\n",
        "\n",
        "This funciton is used to write predictions to output file provided. It internally uses get_final_text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCiPOA7tMPkW"
      },
      "source": [
        "def get_final_text(pred_text, orig_text, do_lower_case):\n",
        "  \"\"\"Project the tokenized prediction back to the original text.\"\"\"\n",
        "\n",
        "  def _strip_spaces(text):\n",
        "    ns_chars = []\n",
        "    ns_to_s_map = collections.OrderedDict()\n",
        "    for (i, c) in enumerate(text):\n",
        "      if c == \" \":\n",
        "        continue\n",
        "      ns_to_s_map[len(ns_chars)] = i\n",
        "      ns_chars.append(c)\n",
        "    ns_text = \"\".join(ns_chars)\n",
        "    return (ns_text, ns_to_s_map)\n",
        "\n",
        "  tokenizer = tokenization.BasicTokenizer(do_lower_case=do_lower_case)\n",
        "\n",
        "  tok_text = \" \".join(tokenizer.tokenize(orig_text))\n",
        "\n",
        "  start_position = tok_text.find(pred_text)\n",
        "  if start_position == -1:\n",
        "    if True:\n",
        "      tf.logging.info(\n",
        "          \"Unable to find text: '%s' in '%s'\" % (pred_text, orig_text))\n",
        "    return orig_text\n",
        "  end_position = start_position + len(pred_text) - 1\n",
        "\n",
        "  (orig_ns_text, orig_ns_to_s_map) = _strip_spaces(orig_text)\n",
        "  (tok_ns_text, tok_ns_to_s_map) = _strip_spaces(tok_text)\n",
        "\n",
        "  if len(orig_ns_text) != len(tok_ns_text):\n",
        "    if True:\n",
        "      tf.logging.info(\"Length not equal after stripping spaces: '%s' vs '%s'\",\n",
        "                      orig_ns_text, tok_ns_text)\n",
        "    return orig_text\n",
        "\n",
        "  # We then project the characters in `pred_text` back to `orig_text` using\n",
        "  # the character-to-character alignment.\n",
        "  tok_s_to_ns_map = {}\n",
        "  for (i, tok_index) in six.iteritems(tok_ns_to_s_map):\n",
        "    tok_s_to_ns_map[tok_index] = i\n",
        "\n",
        "  orig_start_position = None\n",
        "  if start_position in tok_s_to_ns_map:\n",
        "    ns_start_position = tok_s_to_ns_map[start_position]\n",
        "    if ns_start_position in orig_ns_to_s_map:\n",
        "      orig_start_position = orig_ns_to_s_map[ns_start_position]\n",
        "\n",
        "  if orig_start_position is None:\n",
        "    if True:\n",
        "      tf.logging.info(\"Couldn't map start position\")\n",
        "    return orig_text\n",
        "\n",
        "  orig_end_position = None\n",
        "  if end_position in tok_s_to_ns_map:\n",
        "    ns_end_position = tok_s_to_ns_map[end_position]\n",
        "    if ns_end_position in orig_ns_to_s_map:\n",
        "      orig_end_position = orig_ns_to_s_map[ns_end_position]\n",
        "\n",
        "  if orig_end_position is None:\n",
        "    if True:\n",
        "      tf.logging.info(\"Couldn't map end position\")\n",
        "    return orig_text\n",
        "\n",
        "  output_text = orig_text[orig_start_position:(orig_end_position + 1)]\n",
        "  return output_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFm7pZtk8a3L"
      },
      "source": [
        "def write_predictions(all_examples, all_features, all_results, n_best_size,\n",
        "                      max_answer_length, do_lower_case, output_prediction_file,\n",
        "                      output_nbest_file, output_null_log_odds_file):\n",
        "  \"\"\"Write final predictions to the json file and log-odds of null if needed.\"\"\"\n",
        "  \n",
        "  tf.logging.info(\"Writing predictions to: %s\" % (output_prediction_file))\n",
        "  tf.logging.info(\"Writing nbest to: %s\" % (output_nbest_file))\n",
        "\n",
        "  example_index_to_features = collections.defaultdict(list)\n",
        "  for feature in all_features:\n",
        "    example_index_to_features[feature.example_index].append(feature)\n",
        "\n",
        "  unique_id_to_result = {}\n",
        "  for result in all_results:\n",
        "    unique_id_to_result[result.unique_id] = result\n",
        "\n",
        "  _PrelimPrediction = collections.namedtuple(  # pylint: disable=invalid-name\n",
        "      \"PrelimPrediction\",\n",
        "      [\"feature_index\", \"start_index\", \"end_index\", \"start_logit\", \"end_logit\"])\n",
        "\n",
        "  all_predictions = collections.OrderedDict()\n",
        "  all_nbest_json = collections.OrderedDict()\n",
        "  scores_diff_json = collections.OrderedDict()\n",
        "\n",
        "  for (example_index, example) in enumerate(all_examples):\n",
        "    features = example_index_to_features[example_index]\n",
        "\n",
        "    prelim_predictions = []\n",
        "    # keep track of the minimum score of null start+end of position 0\n",
        "    score_null = 1000000  # large and positive\n",
        "    min_null_feature_index = 0  # the paragraph slice with min mull score\n",
        "    null_start_logit = 0  # the start logit at the slice with min null score\n",
        "    null_end_logit = 0  # the end logit at the slice with min null score\n",
        "    for (feature_index, feature) in enumerate(features):\n",
        "      result = unique_id_to_result[feature.unique_id]\n",
        "      start_indexes = run_squad._get_best_indexes(result.start_logits, n_best_size)\n",
        "      end_indexes = run_squad._get_best_indexes(result.end_logits, n_best_size)\n",
        "      # if we could have irrelevant answers, get the min score of irrelevant\n",
        "      if False:\n",
        "        feature_null_score = result.start_logits[0] + result.end_logits[0]\n",
        "        if feature_null_score < score_null:\n",
        "          score_null = feature_null_score\n",
        "          min_null_feature_index = feature_index\n",
        "          null_start_logit = result.start_logits[0]\n",
        "          null_end_logit = result.end_logits[0]\n",
        "      for start_index in start_indexes:\n",
        "        for end_index in end_indexes:\n",
        "          # We could hypothetically create invalid predictions, e.g., predict\n",
        "          # that the start of the span is in the question. We throw out all\n",
        "          # invalid predictions.\n",
        "          if start_index >= len(feature.tokens):\n",
        "            continue\n",
        "          if end_index >= len(feature.tokens):\n",
        "            continue\n",
        "          if start_index not in feature.token_to_orig_map:\n",
        "            continue\n",
        "          if end_index not in feature.token_to_orig_map:\n",
        "            continue\n",
        "          if not feature.token_is_max_context.get(start_index, False):\n",
        "            continue\n",
        "          if end_index < start_index:\n",
        "            continue\n",
        "          length = end_index - start_index + 1\n",
        "          if length > max_answer_length:\n",
        "            continue\n",
        "          prelim_predictions.append(\n",
        "              _PrelimPrediction(\n",
        "                  feature_index=feature_index,\n",
        "                  start_index=start_index,\n",
        "                  end_index=end_index,\n",
        "                  start_logit=result.start_logits[start_index],\n",
        "                  end_logit=result.end_logits[end_index]))\n",
        "\n",
        "    if False:\n",
        "      prelim_predictions.append(\n",
        "          _PrelimPrediction(\n",
        "              feature_index=min_null_feature_index,\n",
        "              start_index=0,\n",
        "              end_index=0,\n",
        "              start_logit=null_start_logit,\n",
        "              end_logit=null_end_logit))\n",
        "    prelim_predictions = sorted(\n",
        "        prelim_predictions,\n",
        "        key=lambda x: (x.start_logit + x.end_logit),\n",
        "        reverse=True)\n",
        "\n",
        "    _NbestPrediction = collections.namedtuple(  # pylint: disable=invalid-name\n",
        "        \"NbestPrediction\", [\"text\", \"start_logit\", \"end_logit\"])\n",
        "\n",
        "    seen_predictions = {}\n",
        "    nbest = []\n",
        "    for pred in prelim_predictions:\n",
        "      if len(nbest) >= n_best_size:\n",
        "        break\n",
        "      feature = features[pred.feature_index]\n",
        "      if pred.start_index > 0:  # this is a non-null prediction\n",
        "        tok_tokens = feature.tokens[pred.start_index:(pred.end_index + 1)]\n",
        "        orig_doc_start = feature.token_to_orig_map[pred.start_index]\n",
        "        orig_doc_end = feature.token_to_orig_map[pred.end_index]\n",
        "        orig_tokens = example.doc_tokens[orig_doc_start:(orig_doc_end + 1)]\n",
        "        tok_text = \" \".join(tok_tokens)\n",
        "\n",
        "        # De-tokenize WordPieces that have been split off.\n",
        "        tok_text = tok_text.replace(\" ##\", \"\")\n",
        "        tok_text = tok_text.replace(\"##\", \"\")\n",
        "\n",
        "        # Clean whitespace\n",
        "        tok_text = tok_text.strip()\n",
        "        tok_text = \" \".join(tok_text.split())\n",
        "        orig_text = \" \".join(orig_tokens)\n",
        "\n",
        "        final_text = get_final_text(tok_text, orig_text, do_lower_case)\n",
        "        if final_text in seen_predictions:\n",
        "          continue\n",
        "\n",
        "        seen_predictions[final_text] = True\n",
        "      else:\n",
        "        final_text = \"\"\n",
        "        seen_predictions[final_text] = True\n",
        "\n",
        "      nbest.append(\n",
        "          _NbestPrediction(\n",
        "              text=final_text,\n",
        "              start_logit=pred.start_logit,\n",
        "              end_logit=pred.end_logit))\n",
        "\n",
        "    # if we didn't inlude the empty option in the n-best, inlcude it\n",
        "    if False:\n",
        "      if \"\" not in seen_predictions:\n",
        "        nbest.append(\n",
        "            _NbestPrediction(\n",
        "                text=\"\", start_logit=null_start_logit,\n",
        "                end_logit=null_end_logit))\n",
        "    # In very rare edge cases we could have no valid predictions. So we\n",
        "    # just create a nonce prediction in this case to avoid failure.\n",
        "    if not nbest:\n",
        "      nbest.append(\n",
        "          _NbestPrediction(text=\"empty\", start_logit=0.0, end_logit=0.0))\n",
        "\n",
        "    assert len(nbest) >= 1\n",
        "\n",
        "    total_scores = []\n",
        "    best_non_null_entry = None\n",
        "    for entry in nbest:\n",
        "      total_scores.append(entry.start_logit + entry.end_logit)\n",
        "      if not best_non_null_entry:\n",
        "        if entry.text:\n",
        "          best_non_null_entry = entry\n",
        "\n",
        "    probs = run_squad._compute_softmax(total_scores)\n",
        "\n",
        "    nbest_json = []\n",
        "    for (i, entry) in enumerate(nbest):\n",
        "      output = collections.OrderedDict()\n",
        "      output[\"text\"] = entry.text\n",
        "      output[\"probability\"] = probs[i]\n",
        "      output[\"start_logit\"] = entry.start_logit\n",
        "      output[\"end_logit\"] = entry.end_logit\n",
        "      nbest_json.append(output)\n",
        "\n",
        "    assert len(nbest_json) >= 1\n",
        "\n",
        "    if not False:\n",
        "      all_predictions[example.qas_id] = nbest_json[0][\"text\"]\n",
        "    else:\n",
        "      # predict \"\" iff the null score - the score of best non-null > threshold\n",
        "      score_diff = score_null - best_non_null_entry.start_logit - (\n",
        "          best_non_null_entry.end_logit)\n",
        "      scores_diff_json[example.qas_id] = score_diff\n",
        "      if score_diff > 0.0:\n",
        "        all_predictions[example.qas_id] = \"\"\n",
        "      else:\n",
        "        all_predictions[example.qas_id] = best_non_null_entry.text\n",
        "\n",
        "    all_nbest_json[example.qas_id] = nbest_json\n",
        "\n",
        "  with tf.gfile.GFile(output_prediction_file, \"w\") as writer:\n",
        "    writer.write(json.dumps(all_predictions, indent=4) + \"\\n\")\n",
        "\n",
        "  with tf.gfile.GFile(output_nbest_file, \"w\") as writer:\n",
        "    writer.write(json.dumps(all_nbest_json, indent=4) + \"\\n\")\n",
        "\n",
        "  if False:\n",
        "    with tf.gfile.GFile(output_null_log_odds_file, \"w\") as writer:\n",
        "      writer.write(json.dumps(scores_diff_json, indent=4) + \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t1tO4T2rkxW"
      },
      "source": [
        "**Model Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4lgBNxxeRFO"
      },
      "source": [
        "# Model Hyper Parameters\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "LEARNING_RATE = 3e-5\n",
        "NUM_TRAIN_EPOCHS = 2.0\n",
        "WARMUP_PROPORTION = 0.1\n",
        "MAX_SEQ_LENGTH = 256\n",
        "EVAL_BATCH_SIZE = 8\n",
        "\n",
        "tpu_cluster_resolver = None\n",
        "SAVE_CHECKPOINTS_STEPS = 1000\n",
        "ITERATIONS_PER_LOOP = 1000\n",
        "NUM_TPU_CORES = 8\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQLBq4mDtXLY"
      },
      "source": [
        "**Tokenizer**:\n",
        "\n",
        "Takes vocab file as input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWyjV9dReFNG"
      },
      "source": [
        "tokenizer = tokenization.FullTokenizer(vocab_file=VOCAB_FILE, do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qsQtbit0cyH"
      },
      "source": [
        "**Tokenization examples**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoLIIRWr0cyH",
        "outputId": "1083c632-663d-4938-d12b-5c41d2381182"
      },
      "source": [
        "tokenizer.tokenize(\"This is a different and longer example to check the 'Tokenization'.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this',\n",
              " 'is',\n",
              " 'a',\n",
              " 'different',\n",
              " 'and',\n",
              " 'longer',\n",
              " 'example',\n",
              " 'to',\n",
              " 'check',\n",
              " 'the',\n",
              " \"'\",\n",
              " 'token',\n",
              " '##ization',\n",
              " \"'\",\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Qe8kzaZqthS6",
        "outputId": "2f3b1eee-c506-42c1-b6c1-79e06694066c"
      },
      "source": [
        "tokenizer.tokenize(\"this is demo example for tokenizer\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this', 'is', 'demo', 'example', 'for', 'token', '##izer']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaOHcUDHeXGm"
      },
      "source": [
        "num_train_steps = int(\n",
        "    len(train_examples) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMQEPmSvgar0"
      },
      "source": [
        "# Setup TPU related config\n",
        "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "NUM_TPU_CORES = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzzE4xH5ubyM"
      },
      "source": [
        "**model function builds model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD5amWrgenU-"
      },
      "source": [
        "model_fn = run_squad.model_fn_builder(\n",
        "    bert_config=modeling.BertConfig.from_json_file(CONFIG_FILE),\n",
        "    init_checkpoint=INIT_CHECKPOINT,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    num_train_steps=num_train_steps,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    use_tpu=True, #If False training will fall on CPU or GPU, depending on what is available  \n",
        "    use_one_hot_embeddings=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-TnyzNUe48M"
      },
      "source": [
        "run_config = tf.contrib.tpu.RunConfig(\n",
        "    cluster=tpu_cluster_resolver,\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=ITERATIONS_PER_LOOP,\n",
        "        num_shards=NUM_TPU_CORES,\n",
        "        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "7jE3VBLFe_S-",
        "outputId": "f811dbd2-b6ba-44f1-dc95-cc087a42183c"
      },
      "source": [
        "estimator = tf.contrib.tpu.TPUEstimator(\n",
        "    use_tpu=True, #If False training will fall on CPU or GPU, depending on what is available \n",
        "    model_fn=model_fn,\n",
        "    config=run_config,\n",
        "    train_batch_size=TRAIN_BATCH_SIZE,\n",
        "    predict_batch_size=EVAL_BATCH_SIZE,\n",
        "    eval_batch_size=EVAL_BATCH_SIZE)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0827 06:18:43.056533 140491252946816 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fc65e7fe950>) includes params argument, but params are not passed to Estimator.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "DPtSzrrqfQB_",
        "outputId": "3ddc953b-28bc-49c9-81bd-1346ba9f9612"
      },
      "source": [
        "print('Please wait...')\n",
        "train_writer = run_squad.FeatureWriter(\n",
        "        filename=os.path.join(OUTPUT_DIR, \"train.tf_record\"),\n",
        "        is_training=True)\n",
        "\n",
        "\n",
        "def append_feature(feature):\n",
        "  train_features.append(feature)\n",
        "  train_writer.process_feature(feature)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0827 06:18:46.242335 140491252946816 deprecation_wrapper.py:119] From bert_repo/run_squad.py:1065: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Please wait...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRX_QJF2ZlSE"
      },
      "source": [
        "### convert_examples_to_features\n",
        "\n",
        "This function converts train examples got from read_squad_examples to features that can be fed to BERT model. It returns all features in InputFeatures class object.\n",
        "\n",
        "**Input Feature class schema:**\n",
        "\n",
        "    unique_id,<br>\n",
        "    example_index,<br>\n",
        "    doc_span_index,<br>\n",
        "    tokens,<br>\n",
        "    token_to_orig_map,<br>\n",
        "    token_is_max_context,<br>\n",
        "    input_ids,<br>\n",
        "    input_mask,<br>\n",
        "    segment_ids,<br>\n",
        "    start_position=None,<br>\n",
        "    end_position=None,<br>\n",
        "    is_impossible=None<br>\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "jyv03G3YfZUr",
        "outputId": "fcbcf838-d72d-497d-8a1a-56210481b3fe"
      },
      "source": [
        "train_features = []\n",
        "\n",
        "run_squad.convert_examples_to_features(train_examples, tokenizer, MAX_SEQ_LENGTH, 128, 64, True, output_fn=append_feature)\n",
        "\n",
        "train_writer.close()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0827 06:18:47.903628 140491252946816 deprecation_wrapper.py:119] From bert_repo/run_squad.py:431: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "1NgUx1icdmQ8",
        "outputId": "ffa2dbc4-113b-4a48-fef6-81e12ab6bab0"
      },
      "source": [
        "print(\"example to feature :\")\n",
        "print(type(train_features[0]))\n",
        "print(\"-\"*70)\n",
        "print(\"unique_id : \",train_features[0].unique_id)\n",
        "print(\"-\"*70)\n",
        "print(\"example_index :\",train_features[0].example_index)\n",
        "print(\"-\"*70)\n",
        "print(\"doc_span_index :\",train_features[0].doc_span_index)\n",
        "print(\"-\"*70)\n",
        "print(\"tokens :\")\n",
        "print(train_features[0].tokens)\n",
        "print(\"-\"*70)\n",
        "print(\"token_to_orig_map :\")\n",
        "print(train_features[0].token_to_orig_map)\n",
        "print(\"-\"*70)\n",
        "print(\"token_is_max_context :\")\n",
        "print(train_features[0].token_is_max_context)\n",
        "print(\"-\"*70)\n",
        "print(\"input_ids :\")\n",
        "print(train_features[0].input_ids)\n",
        "print(\"-\"*70)\n",
        "print(\"segment_ids :\")\n",
        "print(train_features[0].segment_ids)\n",
        "print(\"-\"*70)\n",
        "print(\"start_position : \",train_features[0].start_position)\n",
        "print(\"-\"*70)\n",
        "print(\"end_position :\",train_features[0].end_position)\n",
        "print(\"-\"*70)\n",
        "print(\"is_impossible :\",train_features[0].is_impossible)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "example to feature :\n",
            "<class 'run_squad.InputFeatures'>\n",
            "----------------------------------------------------------------------\n",
            "unique_id :  1000000000\n",
            "----------------------------------------------------------------------\n",
            "example_index : 0\n",
            "----------------------------------------------------------------------\n",
            "doc_span_index : 0\n",
            "----------------------------------------------------------------------\n",
            "tokens :\n",
            "['[CLS]', 'to', 'whom', 'did', 'the', 'virgin', 'mary', 'allegedly', 'appear', 'in', '1858', 'in', 'lou', '##rdes', 'france', '?', '[SEP]', 'architectural', '##ly', ',', 'the', 'school', 'has', 'a', 'catholic', 'character', '.', 'atop', 'the', 'main', 'building', \"'\", 's', 'gold', 'dome', 'is', 'a', 'golden', 'statue', 'of', 'the', 'virgin', 'mary', '.', 'immediately', 'in', 'front', 'of', 'the', 'main', 'building', 'and', 'facing', 'it', ',', 'is', 'a', 'copper', 'statue', 'of', 'christ', 'with', 'arms', 'up', '##rai', '##sed', 'with', 'the', 'legend', '\"', 've', '##ni', '##te', 'ad', 'me', 'om', '##nes', '\"', '.', 'next', 'to', 'the', 'main', 'building', 'is', 'the', 'basilica', 'of', 'the', 'sacred', 'heart', '.', 'immediately', 'behind', 'the', 'basilica', 'is', 'the', 'gr', '##otto', ',', 'a', 'marian', 'place', 'of', 'prayer', 'and', 'reflection', '.', 'it', 'is', 'a', 'replica', 'of', 'the', 'gr', '##otto', 'at', 'lou', '##rdes', ',', 'france', 'where', 'the', 'virgin', 'mary', 'reputed', '##ly', 'appeared', 'to', 'saint', 'bern', '##ade', '##tte', 'so', '##ub', '##iro', '##us', 'in', '1858', '.', 'at', 'the', 'end', 'of', 'the', 'main', 'drive', '(', 'and', 'in', 'a', 'direct', 'line', 'that', 'connects', 'through', '3', 'statues', 'and', 'the', 'gold', 'dome', ')', ',', 'is', 'a', 'simple', ',', 'modern', 'stone', 'statue', 'of', 'mary', '.', '[SEP]']\n",
            "----------------------------------------------------------------------\n",
            "token_to_orig_map :\n",
            "{17: 0, 18: 0, 19: 0, 20: 1, 21: 2, 22: 3, 23: 4, 24: 5, 25: 6, 26: 6, 27: 7, 28: 8, 29: 9, 30: 10, 31: 10, 32: 10, 33: 11, 34: 12, 35: 13, 36: 14, 37: 15, 38: 16, 39: 17, 40: 18, 41: 19, 42: 20, 43: 20, 44: 21, 45: 22, 46: 23, 47: 24, 48: 25, 49: 26, 50: 27, 51: 28, 52: 29, 53: 30, 54: 30, 55: 31, 56: 32, 57: 33, 58: 34, 59: 35, 60: 36, 61: 37, 62: 38, 63: 39, 64: 39, 65: 39, 66: 40, 67: 41, 68: 42, 69: 43, 70: 43, 71: 43, 72: 43, 73: 44, 74: 45, 75: 46, 76: 46, 77: 46, 78: 46, 79: 47, 80: 48, 81: 49, 82: 50, 83: 51, 84: 52, 85: 53, 86: 54, 87: 55, 88: 56, 89: 57, 90: 58, 91: 58, 92: 59, 93: 60, 94: 61, 95: 62, 96: 63, 97: 64, 98: 65, 99: 65, 100: 65, 101: 66, 102: 67, 103: 68, 104: 69, 105: 70, 106: 71, 107: 72, 108: 72, 109: 73, 110: 74, 111: 75, 112: 76, 113: 77, 114: 78, 115: 79, 116: 79, 117: 80, 118: 81, 119: 81, 120: 81, 121: 82, 122: 83, 123: 84, 124: 85, 125: 86, 126: 87, 127: 87, 128: 88, 129: 89, 130: 90, 131: 91, 132: 91, 133: 91, 134: 92, 135: 92, 136: 92, 137: 92, 138: 93, 139: 94, 140: 94, 141: 95, 142: 96, 143: 97, 144: 98, 145: 99, 146: 100, 147: 101, 148: 102, 149: 102, 150: 103, 151: 104, 152: 105, 153: 106, 154: 107, 155: 108, 156: 109, 157: 110, 158: 111, 159: 112, 160: 113, 161: 114, 162: 115, 163: 115, 164: 115, 165: 116, 166: 117, 167: 118, 168: 118, 169: 119, 170: 120, 171: 121, 172: 122, 173: 123, 174: 123}\n",
            "----------------------------------------------------------------------\n",
            "token_is_max_context :\n",
            "{17: True, 18: True, 19: True, 20: True, 21: True, 22: True, 23: True, 24: True, 25: True, 26: True, 27: True, 28: True, 29: True, 30: True, 31: True, 32: True, 33: True, 34: True, 35: True, 36: True, 37: True, 38: True, 39: True, 40: True, 41: True, 42: True, 43: True, 44: True, 45: True, 46: True, 47: True, 48: True, 49: True, 50: True, 51: True, 52: True, 53: True, 54: True, 55: True, 56: True, 57: True, 58: True, 59: True, 60: True, 61: True, 62: True, 63: True, 64: True, 65: True, 66: True, 67: True, 68: True, 69: True, 70: True, 71: True, 72: True, 73: True, 74: True, 75: True, 76: True, 77: True, 78: True, 79: True, 80: True, 81: True, 82: True, 83: True, 84: True, 85: True, 86: True, 87: True, 88: True, 89: True, 90: True, 91: True, 92: True, 93: True, 94: True, 95: True, 96: True, 97: True, 98: True, 99: True, 100: True, 101: True, 102: True, 103: True, 104: True, 105: True, 106: True, 107: True, 108: True, 109: True, 110: True, 111: True, 112: True, 113: True, 114: True, 115: True, 116: True, 117: True, 118: True, 119: True, 120: True, 121: True, 122: True, 123: True, 124: True, 125: True, 126: True, 127: True, 128: True, 129: True, 130: True, 131: True, 132: True, 133: True, 134: True, 135: True, 136: True, 137: True, 138: True, 139: True, 140: True, 141: True, 142: True, 143: True, 144: True, 145: True, 146: True, 147: True, 148: True, 149: True, 150: True, 151: True, 152: True, 153: True, 154: True, 155: True, 156: True, 157: True, 158: True, 159: True, 160: True, 161: True, 162: True, 163: True, 164: True, 165: True, 166: True, 167: True, 168: True, 169: True, 170: True, 171: True, 172: True, 173: True, 174: True}\n",
            "----------------------------------------------------------------------\n",
            "input_ids :\n",
            "[101, 2000, 3183, 2106, 1996, 6261, 2984, 9382, 3711, 1999, 8517, 1999, 10223, 26371, 2605, 1029, 102, 6549, 2135, 1010, 1996, 2082, 2038, 1037, 3234, 2839, 1012, 10234, 1996, 2364, 2311, 1005, 1055, 2751, 8514, 2003, 1037, 3585, 6231, 1997, 1996, 6261, 2984, 1012, 3202, 1999, 2392, 1997, 1996, 2364, 2311, 1998, 5307, 2009, 1010, 2003, 1037, 6967, 6231, 1997, 4828, 2007, 2608, 2039, 14995, 6924, 2007, 1996, 5722, 1000, 2310, 3490, 2618, 4748, 2033, 18168, 5267, 1000, 1012, 2279, 2000, 1996, 2364, 2311, 2003, 1996, 13546, 1997, 1996, 6730, 2540, 1012, 3202, 2369, 1996, 13546, 2003, 1996, 24665, 23052, 1010, 1037, 14042, 2173, 1997, 7083, 1998, 9185, 1012, 2009, 2003, 1037, 15059, 1997, 1996, 24665, 23052, 2012, 10223, 26371, 1010, 2605, 2073, 1996, 6261, 2984, 22353, 2135, 2596, 2000, 3002, 16595, 9648, 4674, 2061, 12083, 9711, 2271, 1999, 8517, 1012, 2012, 1996, 2203, 1997, 1996, 2364, 3298, 1006, 1998, 1999, 1037, 3622, 2240, 2008, 8539, 2083, 1017, 11342, 1998, 1996, 2751, 8514, 1007, 1010, 2003, 1037, 3722, 1010, 2715, 2962, 6231, 1997, 2984, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "----------------------------------------------------------------------\n",
            "segment_ids :\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "----------------------------------------------------------------------\n",
            "start_position :  130\n",
            "----------------------------------------------------------------------\n",
            "end_position : 137\n",
            "----------------------------------------------------------------------\n",
            "is_impossible : False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "n300ueTn0ghL",
        "outputId": "316328ac-8680-4f60-b09b-bfa796508835"
      },
      "source": [
        "print(len(train_examples))\n",
        "print(len(train_features))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "87599\n",
            "97077\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5m34tGhux_B"
      },
      "source": [
        "tf.logging.set_verbosity(tf.logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSgVGyZVvkZF"
      },
      "source": [
        "### Loss Function :\n",
        "\n",
        "* It uses **categotical crossentropy** loss function internally.\n",
        "* Calcaulates loss seperately for start_token and end_token\n",
        "* total loss is average of start and end loss\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "qs0Q9Dxffxvz",
        "outputId": "4be81d97-eea5-4750-ecb3-6c078b49d11d"
      },
      "source": [
        "print('***** Started training at {} *****'.format(datetime.datetime.now()))\n",
        "print('  Num examples = {}'.format(len(train_examples)))\n",
        "print('  Batch size = {}'.format(TRAIN_BATCH_SIZE))\n",
        "\n",
        "\n",
        "tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
        "train_input_fn = run_squad.input_fn_builder(\n",
        "    input_file=train_writer.filename,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=True)\n",
        "\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "print('***** Finished training at {} *****'.format(datetime.datetime.now()))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I0827 06:24:27.257017 140491252946816 <ipython-input-41-9544e7b43547>:6]   Num steps = 10949\n",
            "W0827 06:24:27.258475 140491252946816 deprecation_wrapper.py:119] From bert_repo/run_squad.py:691: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** Started training at 2019-08-27 06:24:27.255979 *****\n",
            "  Num examples = 87599\n",
            "  Batch size = 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0827 06:24:28.046493 140491252946816 estimator.py:360] Skipping training since max_steps has already saved.\n",
            "I0827 06:24:28.047625 140491252946816 error_handling.py:96] training_loop marked as finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** Finished training at 2019-08-27 06:24:28.050430 *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfzCy_Xvs_c-"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_M87dhkgGI-"
      },
      "source": [
        "eval_examples = read_squad_examples(\"/content/dev-v1.1.json\",False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "nzCLI0J_VvFs",
        "outputId": "c6f3839d-3dc5-432d-e38b-2946e1d1ef3c"
      },
      "source": [
        "print(\"type of eval \",type(eval_examples))\n",
        "print(\"-\"*60)\n",
        "print(eval_examples[0].qas_id)\n",
        "print(\"-\"*60)\n",
        "print(eval_examples[0].doc_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "type of eval  <class 'list'>\n",
            "------------------------------------------------------------\n",
            "56be4db0acb8001400a502ec\n",
            "------------------------------------------------------------\n",
            "['Super', 'Bowl', '50', 'was', 'an', 'American', 'football', 'game', 'to', 'determine', 'the', 'champion', 'of', 'the', 'National', 'Football', 'League', '(NFL)', 'for', 'the', '2015', 'season.', 'The', 'American', 'Football', 'Conference', '(AFC)', 'champion', 'Denver', 'Broncos', 'defeated', 'the', 'National', 'Football', 'Conference', '(NFC)', 'champion', 'Carolina', 'Panthers', '24–10', 'to', 'earn', 'their', 'third', 'Super', 'Bowl', 'title.', 'The', 'game', 'was', 'played', 'on', 'February', '7,', '2016,', 'at', \"Levi's\", 'Stadium', 'in', 'the', 'San', 'Francisco', 'Bay', 'Area', 'at', 'Santa', 'Clara,', 'California.', 'As', 'this', 'was', 'the', '50th', 'Super', 'Bowl,', 'the', 'league', 'emphasized', 'the', '\"golden', 'anniversary\"', 'with', 'various', 'gold-themed', 'initiatives,', 'as', 'well', 'as', 'temporarily', 'suspending', 'the', 'tradition', 'of', 'naming', 'each', 'Super', 'Bowl', 'game', 'with', 'Roman', 'numerals', '(under', 'which', 'the', 'game', 'would', 'have', 'been', 'known', 'as', '\"Super', 'Bowl', 'L\"),', 'so', 'that', 'the', 'logo', 'could', 'prominently', 'feature', 'the', 'Arabic', 'numerals', '50.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9slcIN5rMTg"
      },
      "source": [
        "eval_writer = run_squad.FeatureWriter(\n",
        "    filename=os.path.join(OUTPUT_DIR, \"eval.tf_record\"),\n",
        "    is_training=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRjCtUFDs2YJ"
      },
      "source": [
        "\n",
        "def append_feature(feature):\n",
        "    eval_features.append(feature)\n",
        "    eval_writer.process_feature(feature)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMAfkf8mtBvx"
      },
      "source": [
        "eval_features = []\n",
        "\n",
        "run_squad.convert_examples_to_features(\n",
        "        examples=eval_examples,\n",
        "        tokenizer=tokenizer,\n",
        "        max_seq_length=MAX_SEQ_LENGTH,\n",
        "        doc_stride=128,\n",
        "        max_query_length=64,\n",
        "        is_training=False,\n",
        "        output_fn=append_feature)\n",
        "\n",
        "eval_writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "95IThsb7fFj1",
        "outputId": "5bb4d170-7e69-4dd0-a258-7d538031ca1a"
      },
      "source": [
        "print(len(eval_examples))\n",
        "print(len(eval_features))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10570\n",
            "12006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "tpylUVXBtomL",
        "outputId": "230cdbe7-ca9d-4701-b606-5ae0bbadf8db"
      },
      "source": [
        "tf.logging.info(\"***** Running predictions *****\")\n",
        "tf.logging.info(\"  Num orig examples = %d\", len(eval_examples))\n",
        "tf.logging.info(\"  Num features = %d\", len(eval_features))\n",
        "\n",
        "predict_input_fn = run_squad.input_fn_builder(\n",
        "    input_file=eval_writer.filename,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I0827 06:25:10.172574 140491252946816 <ipython-input-47-84a684c96aaa>:1] ***** Running predictions *****\n",
            "I0827 06:25:10.174535 140491252946816 <ipython-input-47-84a684c96aaa>:2]   Num orig examples = 10570\n",
            "I0827 06:25:10.175938 140491252946816 <ipython-input-47-84a684c96aaa>:3]   Num features = 12006\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNZ9qVjEttui"
      },
      "source": [
        "all_results = []\n",
        "for result in estimator.predict(predict_input_fn, yield_single_examples=True):\n",
        "    if len(all_results) % 1000 == 0:\n",
        "        tf.logging.info(\"Processing example: %d\" % (len(all_results)))\n",
        "    unique_id = int(result[\"unique_ids\"])\n",
        "    start_logits = [float(x) for x in result[\"start_logits\"].flat]\n",
        "    end_logits = [float(x) for x in result[\"end_logits\"].flat]\n",
        "    all_results.append(\n",
        "          run_squad.RawResult(\n",
        "              unique_id=unique_id,\n",
        "              start_logits=start_logits,\n",
        "              end_logits=end_logits))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8j1A-vtSt5gu"
      },
      "source": [
        "output_prediction_file = os.path.join(OUTPUT_DIR, \"predictions.json\")\n",
        "output_nbest_file = os.path.join(OUTPUT_DIR, \"nbest_predictions.json\")\n",
        "output_null_log_odds_file = os.path.join(OUTPUT_DIR, \"null_odds.json\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPhJ3ayze1o4"
      },
      "source": [
        "import collections\n",
        "import json\n",
        "\n",
        "write_predictions(eval_examples, eval_features, all_results,\n",
        "                      20, 30,\n",
        "                      True, output_prediction_file,\n",
        "                      output_nbest_file, output_null_log_odds_file)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5sL74Tg30_w"
      },
      "source": [
        "### F1 Score Calcualtion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfaLVsUE-N14"
      },
      "source": [
        "\n",
        "import re\n",
        "from collections import Counter\n",
        "def normalize_answer(s):\n",
        "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
        "    def remove_articles(text):\n",
        "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return ' '.join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return ''.join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "  \n",
        "def f1_score(prediction, ground_truth):\n",
        "    prediction_tokens = normalize_answer(prediction).split()\n",
        "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
        "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
        "    num_same = sum(common.values())\n",
        "    if num_same == 0:\n",
        "        return 0\n",
        "    precision = 1.0 * num_same / len(prediction_tokens)\n",
        "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "\n",
        "def exact_match_score(prediction, ground_truth):\n",
        "    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n",
        "\n",
        "\n",
        "def metric_max_over_ground_truths(metric_fn, prediction, ground_truths):\n",
        "    scores_for_ground_truths = []\n",
        "    for ground_truth in ground_truths:\n",
        "        score = metric_fn(prediction, ground_truth)\n",
        "        scores_for_ground_truths.append(score)\n",
        "    return max(scores_for_ground_truths)\n",
        "\n",
        "\n",
        "def evaluate(dataset, predictions):\n",
        "    f1 = exact_match = total = 0\n",
        "    for article in dataset:\n",
        "        for paragraph in article['paragraphs']:\n",
        "            for qa in paragraph['qas']:\n",
        "                total += 1\n",
        "                if qa['id'] not in predictions:\n",
        "\n",
        "                    continue\n",
        "                ground_truths = list(map(lambda x: x['text'], qa['answers']))\n",
        "                prediction = predictions[qa['id']]\n",
        "                exact_match += metric_max_over_ground_truths(\n",
        "                    exact_match_score, prediction, ground_truths)\n",
        "                f1 += metric_max_over_ground_truths(\n",
        "                    f1_score, prediction, ground_truths)\n",
        "\n",
        "    exact_match = 100.0 * exact_match / total\n",
        "    f1 = 100.0 * f1 / total\n",
        "\n",
        "    return {'exact_match': exact_match, 'f1': f1}\n",
        "  \n",
        "  \n",
        "def evaluate_squad(data_file,pred_file):\n",
        "  \n",
        "  with open(data_file) as dataset_file:\n",
        "    dataset_json = json.load(dataset_file)\n",
        "    dataset = dataset_json['data']\n",
        "  with open(pred_file) as prediction_file:\n",
        "    predictions = json.load(prediction_file)\n",
        "  print(evaluate(dataset, predictions))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "QDL05DC0my7g",
        "outputId": "d97e6f90-4c39-49e9-d473-97e01b43b834"
      },
      "source": [
        "evaluate_squad(\"/content/dev-v1.1.json\",\"/content/bert-checkpoints_models_SQUAD_predictions.json\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'exact_match': 80.85146641438033, 'f1': 88.0228956599229}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "IplHdvPsr851",
        "outputId": "34eda63b-5753-4144-8f42-ae2536ee9afb"
      },
      "source": [
        "evaluate_squad(\"/content/train-v1.1.json\",\"/content/bert-checkpoints_models_SQUAD_train_predictions.json\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'exact_match': 84.38978240302744,'f1': 90.87081895814865}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}